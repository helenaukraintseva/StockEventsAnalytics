import os
import json
import time
import logging
from dotenv import load_dotenv
import google.generativeai as genai

from langchain.document_loaders import JSONLoader
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document

load_dotenv()
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

GEMINI_API = os.getenv("GEMINI_API_KEY")
GEN_QUERY = os.getenv("GEN_QUERY", "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞")
JSONL_PATH = os.getenv("JSONL_FILE", "rag_data.jsonl")

genai.configure(api_key=GEMINI_API)
model = genai.GenerativeModel("models/gemini-2.0-flash-lite-001")


def load_jsonl_documents(path):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ JSONL-—Ñ–∞–π–ª–∞.
    """
    documents = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            record = json.loads(line)
            documents.append(Document(
                page_content=record["content"],
                metadata={"title": record["title"], "source": record["source"]}
            ))
    return documents


def main():
    start_time = time.time()
    documents = load_jsonl_documents(JSONL_PATH)
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(documents)

    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = FAISS.from_documents(chunks, embeddings)
    retriever = vectorstore.as_retriever()

    docs = retriever.invoke(GEN_QUERY)

    if not docs:
        logging.warning("ü§∑ –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    logging.info("üîé –ù–∞–π–¥–µ–Ω–æ %d —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤", len(docs))
    context = "\n".join([doc.page_content for doc in docs])

    prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {GEN_QUERY}"
    logging.info("‚è≥ –ó–∞–ø—Ä–æ—Å –∫ Gemini...")
    response = model.generate_content(prompt)

    print("\nüß† –û—Ç–≤–µ—Ç –æ—Ç Gemini:")
    print(response.text)
    logging.info("‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: %.2f —Å–µ–∫.", time.time() - start_time)


if __name__ == "__main__":
    main()
