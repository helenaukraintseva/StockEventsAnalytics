from sentence_transformers import SentenceTransformer
from transformers import pipeline
import faiss
import numpy as np
import torch
import time

start_time = time.time()

# --- 1. –î–æ–∫—É–º–µ–Ω—Ç—ã sdff---
documents = [
    "–ë–∏—Ç–∫–æ–∏–Ω ‚Äî —ç—Ç–æ –¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ü–∏—Ñ—Ä–æ–≤–∞—è –≤–∞–ª—é—Ç–∞.",
    "–≠—Ñ–∏—Ä–∏—É–º –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–º–∞—Ä—Ç-–∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –∏ dApp-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.",
    "–ë–ª–æ–∫—á–µ–π–Ω ‚Äî —ç—Ç–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –≤–∏–¥–µ —Ü–µ–ø–æ—á–∫–∏ –±–ª–æ–∫–æ–≤.",
    "–ö–æ—à–µ–ª—ë–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤.",
    "–°—Ç–µ–π–∫–∏–Ω–≥ ‚Äî —ç—Ç–æ —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–∞—Ç—å –¥–æ—Ö–æ–¥ –æ—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–µ—Ç–∏ PoS."
]

# --- 2. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ---
embedder = SentenceTransformer("all-MiniLM-L6-v2")
doc_embeddings = embedder.encode(documents, convert_to_numpy=True)

# --- 3. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è (FAISS) ---
index = faiss.IndexFlatL2(doc_embeddings.shape[1])
index.add(doc_embeddings)

# --- 4. –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å (–¥–ª—è –æ—Ç–≤–µ—Ç–∞) ---
qa_model = pipeline("text2text-generation", model="sberbank-ai/rugpt3small_based_on_gpt2", max_length=100,
                    device=0 if torch.cuda.is_available() else -1)

# --- 5. –í–æ–ø—Ä–æ—Å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
# question = input("‚ùì –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å: ")
question = "—á—Ç–æ —Ç–∞–∫–æ–µ –±–∏—Ç–∫–æ–∏–Ω"
print("time 1:", round(time.time() - start_time))
# --- 6. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫—É—Å–∫–æ–≤ ---
question_embedding = embedder.encode([question], convert_to_numpy=True)
D, I = index.search(question_embedding, k=2)  # —Ç–æ–ø-2 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫—É—Å–∫–∞

retrieved_docs = "\n".join([documents[i] for i in I[0]])

# --- 7. –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ---
prompt = f"–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞:\n{retrieved_docs}\n\n–í–æ–ø—Ä–æ—Å: {question}"
answer = qa_model(prompt)[0]["generated_text"]

print("\nüß† –û—Ç–≤–µ—Ç:", answer)

question = "—á—Ç–æ —Ç–∞–∫–æ–µ –≠—Ñ–∏—Ä–∏—É–º"
print("time 2:", round(time.time() - start_time))
# --- 6. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫—É—Å–∫–æ–≤ ---
question_embedding = embedder.encode([question], convert_to_numpy=True)
D, I = index.search(question_embedding, k=2)  # —Ç–æ–ø-2 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫—É—Å–∫–∞

retrieved_docs = "\n".join([documents[i] for i in I[0]])

# --- 7. –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ---
prompt = f"–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞:\n{retrieved_docs}\n\n–í–æ–ø—Ä–æ—Å: {question}"
answer = qa_model(prompt)[0]["generated_text"]

print("\nüß† –û—Ç–≤–µ—Ç:", answer)
