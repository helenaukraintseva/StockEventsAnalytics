import os
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import CharacterTextSplitter
import time
start_time = time.time()

# === –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ ===
loader = TextLoader("text_1.txt", encoding="utf-8")
documents = loader.load()

# === –®–∞–≥ 2: –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏ ===
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(documents)

# === –®–∞–≥ 3: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ (–ª–æ–∫–∞–ª—å–Ω—ã–µ) ===
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# === –®–∞–≥ 4: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è FAISS ===
vectorstore = FAISS.from_documents(chunks, embeddings)

# === –®–∞–≥ 5: –ü–æ–∏—Å–∫ –∏ –≤—ã–≤–æ–¥ –±–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ===
retriever = vectorstore.as_retriever()
print("Time 1:", round(time.time() - start_time, 2))
# while True:
    # query = input("\n‚ùì –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞): ")
query = "–ß—Ç–æ —Ç–∞–∫–æ–µ RAG"
# if query.lower() in ["exit", "–≤—ã—Ö–æ–¥", "quit"]:
#     break

docs = retriever.get_relevant_documents(query)

if not docs:
    print("ü§∑ –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
else:
    print(f"\nüîé –ù–∞–π–¥–µ–Ω–æ {len(docs)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤:")
    for i, doc in enumerate(docs, 1):
        print(f"\nüìÑ –§—Ä–∞–≥–º–µ–Ω—Ç {i}:\n{doc.page_content}")

print("Time 2:", round(time.time() - start_time, 2))