# rag_ask_fixed.py

import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import time

start_time = time.time()

# --- 1. –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ---
with open("knowledge_base.json", "r", encoding="utf-8") as f:
    documents = json.load(f)

embeddings = np.load("doc_embeddings.npy")
index = faiss.read_index("faiss_index.index")

# --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ---
print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º SentenceTransformer...")
embedder = SentenceTransformer("all-MiniLM-L6-v2")

print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å...")
qa_model = pipeline(
    "text2text-generation",
    model="./rut5-small",
    tokenizer="./rut5-small",
    tokenizer_kwargs={"use_fast": False},  # üîß –ö–ª—é—á–µ–≤–∞—è –ø—Ä–∞–≤–∫–∞
    device=-1  # –ò–ª–∏ 0, –µ—Å–ª–∏ –µ—Å—Ç—å CUDA
)

# --- 3. –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ ---
def answer_question(question, top_k=3):
    question_embedding = embedder.encode([question])
    _, indices = index.search(question_embedding, top_k)
    context = "\n".join([documents[i] for i in indices[0]])

    prompt = f"–í–æ–ø—Ä–æ—Å: {question}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n–û—Ç–≤–µ—Ç:"
    result = qa_model(prompt, max_length=100, do_sample=False)[0]['generated_text']
    return result.strip()

# --- 4. –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ---
user_question = "–ß—Ç–æ —Ç–∞–∫–æ–µ –±–ª–æ–∫—á–µ–π–Ω?"
response = answer_question(user_question)

print("üß† –û—Ç–≤–µ—Ç:", response)
print(f"‚è±Ô∏è Total time: {round(time.time() - start_time, 2)} —Å–µ–∫.")
