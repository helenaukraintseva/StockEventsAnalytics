import os
import pandas as pd
import re

# –ü–∞–ø–∫–∞ —Å CSV-—Ñ–∞–π–ª–∞–º–∏
folder_path = 'datasets'

# –ò–º—è —Å—Ç–æ–ª–±—Ü–∞ —Å —Ü–µ–ª–µ–≤—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
target_column = 'target'

# –ü—Ä–µ–¥–µ–ª—ã –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ
max_per_class = 20000
min_per_class = 8000

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
for filename in os.listdir(folder_path):
    if filename.endswith('.csv'):
        file_path = os.path.join(folder_path, filename)
        print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {filename}")

        df = pd.read_csv(file_path)


        # –ü—Ä–∏–º–µ—Ä –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
        df['some_column'] = df['some_column'].astype(str).apply(
            lambda x: float(re.findall(r'[\d\.E+-]+', x)[0]) if 'np.float64' in x else float(x))
        print("üìè –†–∞–∑–º–µ—Ä:", df.shape)
        print("üìä –ö–æ–ª–æ–Ω–∫–∏:", df.columns.tolist())
        print("üîé –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
        print(df.dtypes)
        print("üîç –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:")
        print(df.head(3))

        #
        # # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
        # if target_column not in df.columns:
        #     print(f"‚ö† –ü—Ä–æ–ø—É—â–µ–Ω–æ: –ù–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ '{target_column}'")
        #     continue
        #
        # # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        # class_counts = df[target_column].value_counts()
        # unique_classes = set(df[target_column].unique())
        # expected_classes = {0, 1, 2}
        #
        # if not unique_classes.issubset(expected_classes):
        #     print(f"‚ö† –ü—Ä–æ–ø—É—â–µ–Ω–æ: –ù–∞–π–¥–µ–Ω—ã –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ ‚Äî {unique_classes}")
        #     continue
        #
        # # –£–¥–æ—Å—Ç–æ–≤–µ—Ä–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–ª–∞—Å—Å—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
        # if not expected_classes.issubset(class_counts.index):
        #     print(f"‚ö† –ü—Ä–æ–ø—É—â–µ–Ω–æ: –ù–µ –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–ª–∞—Å—Å—ã –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö ‚Äî {class_counts.to_dict()}")
        #     continue
        #
        # # –û–ø—Ä–µ–¥–µ–ª–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–∞
        # possible_counts = [class_counts[cls] for cls in expected_classes]
        # min_class_count = min(possible_counts)
        # final_count = min(max(min_class_count, min_per_class), max_per_class)
        #
        # if final_count < min_per_class:
        #     print(f"‚ö† –ü—Ä–æ–ø—É—â–µ–Ω–æ: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ ‚Äî –º–∏–Ω–∏–º—É–º {min_class_count} < {min_per_class}")
        #     continue
        #
        # # –°–±–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º
        # balanced_dfs = []
        # for cls in sorted(expected_classes):
        #     cls_df = df[df[target_column] == cls]
        #     if len(cls_df) >= final_count:
        #         cls_df = cls_df.sample(n=final_count, random_state=42)
        #         balanced_dfs.append(cls_df)
        #     else:
        #         print(f"‚ö† –ö–ª–∞—Å—Å {cls} –∏–º–µ–µ—Ç —Ç–æ–ª—å–∫–æ {len(cls_df)} –∑–∞–ø–∏—Å–µ–π, —Ç—Ä–µ–±—É–µ—Ç—Å—è {final_count}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª.")
        #         break
        # else:
        #     # –ï—Å–ª–∏ –≤—Å–µ –∫–ª–∞—Å—Å—ã –ø—Ä–æ—à–ª–∏, —Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        #     balanced_df = pd.concat(balanced_dfs).sample(frac=1, random_state=42)
        #     balanced_df.to_csv(file_path, index=False)
        #     print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename} (–ø–æ {final_count} —Å—Ç—Ä–æ–∫ –Ω–∞ –∫–ª–∞—Å—Å, –≤—Å–µ–≥–æ {len(balanced_df)} —Å—Ç—Ä–æ–∫)\n")
